{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2c0a8f",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8f9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff552ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATHS = [\n",
    "  \"data/Emotion NLP/goemotions_1.csv\",\n",
    "  \"data/Emotion NLP/goemotions_2.csv\",\n",
    "  \"data/Emotion NLP/goemotions_3.csv\",\n",
    "]\n",
    "\n",
    "KEPT_LABELS = [\n",
    "  \"joy\", \"sadness\", \"anger\", \"fear\",\n",
    "  \"disgust\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "TARGET_MIN_SAMPLES = 1000\n",
    "TARGET_MAX_SAMPLES = 3000\n",
    "MAX_LABEL_FRACTION = 0.30  # no emotion should dominate >30%\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f484a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 211225 total samples\n"
     ]
    }
   ],
   "source": [
    "dfs = [pd.read_csv(path) for path in CSV_PATHS]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} total samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ab6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3411 unclear samples\n"
     ]
    }
   ],
   "source": [
    "if \"example_very_unclear\" in df.columns:\n",
    "  before = len(df)\n",
    "  df = df[df[\"example_very_unclear\"] == False]\n",
    "  print(f\"Dropped {before - len(df)} unclear samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c97ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"id\", \"text\"] + KEPT_LABELS\n",
    "df = df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7dbdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 117116 zero-label samples\n"
     ]
    }
   ],
   "source": [
    "label_sum = df[KEPT_LABELS].sum(axis=1)\n",
    "before = len(df)\n",
    "df = df[label_sum > 0]\n",
    "print(f\"Dropped {before - len(df)} zero-label samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9b326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56dd546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_frequencies(frame):\n",
    "  return frame[KEPT_LABELS].sum() / len(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "361aab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final label distribution:\n",
      "neutral     15148\n",
      "anger        8084\n",
      "joy          7983\n",
      "sadness      6758\n",
      "surprise     5514\n",
      "disgust      5301\n",
      "fear         3197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  freqs = label_frequencies(df)\n",
    "  max_label = freqs.idxmax()\n",
    "  max_frac = freqs[max_label]\n",
    "\n",
    "  if max_frac <= MAX_LABEL_FRACTION:\n",
    "    break\n",
    "\n",
    "  # find rows dominated only by the max label\n",
    "  mask = (df[max_label] == 1) & (df[KEPT_LABELS].sum(axis=1) == 1)\n",
    "  removable = df[mask]\n",
    "\n",
    "  if len(removable) == 0:\n",
    "    break\n",
    "\n",
    "  # remove a small chunk\n",
    "  drop_n = min(50, len(removable))\n",
    "  drop_idx = removable.sample(n=drop_n, random_state=RANDOM_SEED).index\n",
    "  df = df.drop(drop_idx)\n",
    "  \n",
    "\n",
    "print(\"Final label distribution:\")\n",
    "print(df[KEPT_LABELS].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abbe773d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 3000\n"
     ]
    }
   ],
   "source": [
    "if len(df) > TARGET_MAX_SAMPLES:\n",
    "  df = df.sample(n=TARGET_MAX_SAMPLES, random_state=RANDOM_SEED)\n",
    "\n",
    "elif len(df) < TARGET_MIN_SAMPLES:\n",
    "  print(\"Warning: dataset smaller than target minimum\")\n",
    "\n",
    "print(f\"Final dataset size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e55c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frozen evaluation set â†’ data/Emotion NLP/goemotions_eval_set.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = \"data/Emotion NLP/goemotions_eval_set.csv\"\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Saved frozen evaluation set â†’ {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5568b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5c4fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d2a13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEPT_LABELS = [\"joy\", \"sadness\", \"anger\", \"fear\", \"disgust\", \"surprise\", \"neutral\"]\n",
    "DIST_LABELS = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "ROBERTA_LABELS = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"love\", \"optimism\", \"pessimism\", \"sadness\", \"surprise\", \"trust\"]\n",
    "\n",
    "MODEL_NAMES = {\n",
    "  \"distilbert\": [\"bhadresh-savani/distilbert-base-uncased-emotion\", DIST_LABELS],\n",
    "  \"roberta\": [\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\", ROBERTA_LABELS],\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "THRESHOLD = 0.5\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "DATA_PATH = \"data/Emotion NLP/goemotions_eval_set.csv\"\n",
    "OUTPUT_DIR = \"data/Emotion NLP/results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aecbd2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 samples\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "ids = df[\"id\"].tolist()\n",
    "\n",
    "n_samples = len(df)\n",
    "print(f\"Loaded {n_samples} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1de8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, texts, tokenizer):\n",
    "    self.texts = texts\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.tokenizer(\n",
    "      self.texts[idx],\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      max_length=MAX_LENGTH,\n",
    "      return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model_name, hf_name, labels_len):\n",
    "  print(f\"\\nRunning inference: {model_name}\")\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Device: {device}\")\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(hf_name)\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    hf_name,\n",
    "    num_labels=labels_len,\n",
    "    problem_type=\"multi_label_classification\"\n",
    "  )\n",
    "\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  dataset = TextDataset(texts, tokenizer)\n",
    "  dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "  all_probs = []\n",
    "\n",
    "  start_time = time.perf_counter()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "      batch = {k: v.squeeze(1).to(device) for k, v in batch.items()}\n",
    "      outputs = model(**batch)\n",
    "      logits = outputs.logits\n",
    "      probs = torch.sigmoid(logits)\n",
    "      all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "  end_time = time.perf_counter()\n",
    "\n",
    "  probs = np.vstack(all_probs)\n",
    "\n",
    "  timing = {\n",
    "    \"model\": hf_name,\n",
    "    \"device\": str(device),\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_samples\": n_samples,\n",
    "    \"total_inference_time_sec\": round(end_time - start_time, 3),\n",
    "    \"avg_time_per_sample_ms\": round(\n",
    "      (end_time - start_time) / n_samples * 1000, 3\n",
    "    )\n",
    "  }\n",
    "\n",
    "  return probs, timing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edfcedf",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a2f6718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference: distilbert\n",
      "Device: cpu\n",
      "Probabilities shape: (5, 6)\n",
      "Sample probabilities:\n",
      " [[0.97813433 0.7523837  0.09782096 0.48692903 0.2512284  0.04176866]\n",
      " [0.9988959  0.18733689 0.15640457 0.37029728 0.1045764  0.09828914]]\n",
      "Sample predictions:\n",
      " [[1 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]]\n",
      "\n",
      "TEXT: She had really bad chronic back pain from what I can remember, so was self treating with alcohol\n",
      "sadness    â†’ 0.978\n",
      "joy        â†’ 0.752\n",
      "love       â†’ 0.098\n",
      "anger      â†’ 0.487\n",
      "fear       â†’ 0.251\n",
      "surprise   â†’ 0.042\n",
      "\n",
      "TEXT: Ah well I still feel a bit bad for the parrot but at least he wonâ€˜t be harmed :)\n",
      "sadness    â†’ 0.999\n",
      "joy        â†’ 0.187\n",
      "love       â†’ 0.156\n",
      "anger      â†’ 0.370\n",
      "fear       â†’ 0.105\n",
      "surprise   â†’ 0.098\n",
      "\n",
      "TEXT: But is that a good thing though ðŸ¤”ðŸ¤”\n",
      "sadness    â†’ 0.450\n",
      "joy        â†’ 0.993\n",
      "love       â†’ 0.151\n",
      "anger      â†’ 0.336\n",
      "fear       â†’ 0.131\n",
      "surprise   â†’ 0.081\n",
      "\n",
      "TEXT: The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \n",
      "sadness    â†’ 0.284\n",
      "joy        â†’ 0.265\n",
      "love       â†’ 0.093\n",
      "anger      â†’ 0.997\n",
      "fear       â†’ 0.291\n",
      "surprise   â†’ 0.075\n",
      "\n",
      "TEXT: \"*[NAME], what's your favourite 80s band?*\" \"*New ORDERRRR!*\"\n",
      "sadness    â†’ 0.311\n",
      "joy        â†’ 0.996\n",
      "love       â†’ 0.265\n",
      "anger      â†’ 0.205\n",
      "fear       â†’ 0.079\n",
      "surprise   â†’ 0.118\n"
     ]
    }
   ],
   "source": [
    "SANITY_N = 5\n",
    "df_sanity = df.head(SANITY_N)\n",
    "\n",
    "texts = df_sanity[\"text\"].tolist()\n",
    "ids = df_sanity[\"id\"].tolist()\n",
    "\n",
    "\n",
    "probs, timing = run_inference(\n",
    "  model_name=\"distilbert\",\n",
    "  hf_name=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "  labels_len=len(DIST_LABELS)\n",
    ")\n",
    "\n",
    "print(\"Probabilities shape:\", probs.shape)\n",
    "print(\"Sample probabilities:\\n\", probs[:2])\n",
    "\n",
    "preds = (probs >= THRESHOLD).astype(int)\n",
    "print(\"Sample predictions:\\n\", preds[:2])\n",
    "\n",
    "for i in range(df_sanity.shape[0]):\n",
    "  print(\"\\nTEXT:\", texts[i])\n",
    "  for j, label in enumerate(DIST_LABELS):\n",
    "    print(f\"{label:10s} â†’ {probs[i][j]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59feea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference: roberta\n",
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46e1d5e390f497581fbab1d1a1154d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7c97060cf14b2fa8230476df1eb1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e967854cfa2466f975282fd990ee90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678dba9aa4b740e199382f5d0630c6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2a2fc0d0684a1c9c3d52278e8a9fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities shape: (5, 11)\n",
      "Sample probabilities:\n",
      " [[0.22499156 0.05597249 0.35495785 0.07578404 0.01990303 0.00538129\n",
      "  0.0675408  0.5977556  0.94322455 0.01272445 0.00929501]\n",
      " [0.04210198 0.08851668 0.04805688 0.65962917 0.66848457 0.0283549\n",
      "  0.85636437 0.03561831 0.08661252 0.01710225 0.04877528]]\n",
      "Sample predictions:\n",
      " [[0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0 0 0]]\n",
      "\n",
      "TEXT: She had really bad chronic back pain from what I can remember, so was self treating with alcohol\n",
      "sadness    â†’ 0.225\n",
      "joy        â†’ 0.056\n",
      "love       â†’ 0.355\n",
      "anger      â†’ 0.076\n",
      "fear       â†’ 0.020\n",
      "surprise   â†’ 0.005\n",
      "\n",
      "TEXT: Ah well I still feel a bit bad for the parrot but at least he wonâ€˜t be harmed :)\n",
      "sadness    â†’ 0.042\n",
      "joy        â†’ 0.089\n",
      "love       â†’ 0.048\n",
      "anger      â†’ 0.660\n",
      "fear       â†’ 0.668\n",
      "surprise   â†’ 0.028\n",
      "\n",
      "TEXT: But is that a good thing though ðŸ¤”ðŸ¤”\n",
      "sadness    â†’ 0.013\n",
      "joy        â†’ 0.730\n",
      "love       â†’ 0.027\n",
      "anger      â†’ 0.086\n",
      "fear       â†’ 0.444\n",
      "surprise   â†’ 0.012\n",
      "\n",
      "TEXT: The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \n",
      "sadness    â†’ 0.818\n",
      "joy        â†’ 0.422\n",
      "love       â†’ 0.547\n",
      "anger      â†’ 0.016\n",
      "fear       â†’ 0.306\n",
      "surprise   â†’ 0.011\n",
      "\n",
      "TEXT: \"*[NAME], what's your favourite 80s band?*\" \"*New ORDERRRR!*\"\n",
      "sadness    â†’ 0.012\n",
      "joy        â†’ 0.735\n",
      "love       â†’ 0.023\n",
      "anger      â†’ 0.057\n",
      "fear       â†’ 0.701\n",
      "surprise   â†’ 0.059\n"
     ]
    }
   ],
   "source": [
    "probs, timing = run_inference(\n",
    "  model_name=\"roberta\",\n",
    "  hf_name=\"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\",\n",
    "  labels_len=len(ROBERTA_LABELS)\n",
    ")\n",
    "\n",
    "print(\"Probabilities shape:\", probs.shape)\n",
    "print(\"Sample probabilities:\\n\", probs[:2])\n",
    "\n",
    "preds = (probs >= THRESHOLD).astype(int)\n",
    "print(\"Sample predictions:\\n\", preds[:2])\n",
    "\n",
    "for i in range(df_sanity.shape[0]):\n",
    "  print(\"\\nTEXT:\", texts[i])\n",
    "  for j, label in enumerate(DIST_LABELS):\n",
    "    print(f\"{label:10s} â†’ {probs[i][j]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "685bba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# # Load tokenizer\n",
    "# distil_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# # Load model\n",
    "# distil_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "#   \"distilbert-base-uncased\",\n",
    "#   problem_type=\"multi_label_classification\",  # for multi-label\n",
    "#   num_labels=len(kept_labels)               # your 8 labels\n",
    "# )\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# Load tokenizer\n",
    "distil_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load model\n",
    "distil_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "  \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "  problem_type=\"multi_label_classification\",  # for multi-label\n",
    "  num_labels=len([\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"])               # your 8 labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be241bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7838e013cc6c4cdeb136e69645c53159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carli\\.pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\carli\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-emotion-multilabel-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c194dbf8bb48f9893679c606bf4c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "\n",
    "# # Load tokenizer\n",
    "# roberta_tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# # Load model\n",
    "# roberta_model = RobertaForSequenceClassification.from_pretrained(\n",
    "#   \"roberta-base\",\n",
    "#   problem_type=\"multi_label_classification\",\n",
    "#   num_labels=len(kept_labels)\n",
    "# )\n",
    "\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "\n",
    "# Load tokenizer\n",
    "roberta_tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load model\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(\n",
    "  \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\",\n",
    "  problem_type=\"multi_label_classification\",\n",
    "  num_labels=len([\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"love\", \"optimism\", \"pessimism\", \"sadness\", \"surprise\", \"trust\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d02f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick inference\n",
    "import torch\n",
    "\n",
    "def predict(model, tokenizer, texts, threshold=0.5):\n",
    "  inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.sigmoid(outputs.logits)  # multi-label probabilities\n",
    "    preds = (probs >= threshold).int()\n",
    "  return preds, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12692b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0]], dtype=torch.int32),\n",
       " tensor([[0.2172, 0.9986, 0.2412, 0.1349, 0.0895, 0.1017],\n",
       "         [0.9974, 0.1571, 0.0907, 0.4971, 0.2588, 0.0890]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"])\n",
    "predict(distil_model, distil_tokenizer, [\"I am so happy today!\", \"This is terrible...\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e9de69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0]], dtype=torch.int32),\n",
       " tensor([[0.0148, 0.0433, 0.0136, 0.0122, 0.9900, 0.6960, 0.8425, 0.0085, 0.0150,\n",
       "          0.0384, 0.1132],\n",
       "         [0.9562, 0.0266, 0.9608, 0.6311, 0.0089, 0.0081, 0.0064, 0.1003, 0.5182,\n",
       "          0.0625, 0.0075]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print([\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"love\", \"optimism\", \"pessimism\", \"sadness\", \"surprise\", \"trust\"])\n",
    "predict(roberta_model, roberta_tokenizer, [\"I am so happy today!\", \"This is terrible...\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d54b52",
   "metadata": {},
   "source": [
    "## Full Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef131dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference: distilbert\n",
      "Device: cpu\n",
      "Saved â†’ data/Emotion NLP/results//distilbert_predictions.csv\n",
      "Saved â†’ data/Emotion NLP/results//distilbert_timing.json\n",
      "\n",
      "Running inference: roberta\n",
      "Device: cpu\n",
      "Saved â†’ data/Emotion NLP/results//roberta_predictions.csv\n",
      "Saved â†’ data/Emotion NLP/results//roberta_timing.json\n"
     ]
    }
   ],
   "source": [
    "for short_name, (hf_name, labels) in MODEL_NAMES.items():\n",
    "\n",
    "  probs, timing = run_inference(short_name, hf_name, len(labels))\n",
    "\n",
    "  # Convert probabilities â†’ predictions\n",
    "  preds = (probs >= THRESHOLD).astype(int)\n",
    "\n",
    "  # Build output dataframe\n",
    "  out_df = pd.DataFrame({\n",
    "    \"id\": ids,\n",
    "    \"text\": texts\n",
    "  })\n",
    "\n",
    "  for i, label in enumerate(labels):\n",
    "    out_df[f\"conf_{label}\"] = probs[:, i]\n",
    "    out_df[f\"pred_{label}\"] = preds[:, i]\n",
    "\n",
    "  # Save predictions\n",
    "  pred_path = f\"{OUTPUT_DIR}/{short_name}_predictions.csv\"\n",
    "  out_df.to_csv(pred_path, index=False)\n",
    "\n",
    "  # Save timing\n",
    "  timing_path = f\"{OUTPUT_DIR}/{short_name}_timing.json\"\n",
    "  with open(timing_path, \"w\") as f:\n",
    "    json.dump(timing, f, indent=2)\n",
    "\n",
    "  print(f\"Saved â†’ {pred_path}\")\n",
    "  print(f\"Saved â†’ {timing_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe58a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
